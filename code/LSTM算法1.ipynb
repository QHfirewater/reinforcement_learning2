{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9c8323",
   "metadata": {},
   "source": [
    "## Lstm基本方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "233ff682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn             # 神经网络模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4dfd190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.9887e-01, -1.0906e+00, -3.2491e-01,  9.0450e-01,  8.6962e-01,\n",
       "           5.8029e-01,  5.9709e-01,  2.2211e-01,  1.6019e+00, -3.0774e-01],\n",
       "         [-1.3165e+00, -5.5317e-01, -2.4624e-01,  2.3981e-01, -1.6486e+00,\n",
       "           2.2165e+00,  4.2184e-01,  4.2397e-01, -1.1512e+00,  2.1666e+00],\n",
       "         [-1.1043e+00,  5.1162e-01, -2.1645e+00, -6.2635e-02, -1.7110e+00,\n",
       "           2.6152e-01,  6.1497e-01, -2.4625e+00, -6.0482e-02, -2.3050e-01]],\n",
       "\n",
       "        [[ 6.6064e-01,  2.2689e+00,  3.5934e+00, -3.1203e-01, -9.8808e-01,\n",
       "           1.2020e+00,  2.3271e-02,  7.8549e-01, -2.6834e-01, -1.1233e+00],\n",
       "         [-4.3374e-01, -4.7572e-01,  2.0592e+00,  5.3663e-02, -7.8212e-01,\n",
       "           7.0176e-01,  6.8634e-01, -4.3126e-01,  7.9296e-01,  8.9293e-01],\n",
       "         [-5.3938e-01,  2.0193e+00,  1.6906e-01,  3.9988e-01,  2.4367e-01,\n",
       "           4.1347e-01, -1.2240e+00,  2.8946e-03, -8.5198e-01, -7.9133e-01]],\n",
       "\n",
       "        [[ 5.4147e-01, -3.3297e-01,  1.3279e-01,  1.6706e+00,  1.5328e+00,\n",
       "           6.3603e-01,  1.3108e+00,  1.0515e+00, -3.0188e-01, -1.3019e+00],\n",
       "         [-2.7042e-01,  2.4957e-01, -8.7100e-02, -1.0676e+00,  4.8892e-02,\n",
       "          -5.0072e-01, -7.9780e-01,  9.6464e-02,  2.0131e+00, -1.3064e+00],\n",
       "         [-4.8459e-01,  2.0755e+00, -4.0179e-02, -8.9831e-01,  1.2816e+00,\n",
       "          -6.3020e-01, -2.0721e-01, -1.2792e+00, -1.3759e+00, -1.6274e+00]],\n",
       "\n",
       "        [[ 1.5619e+00, -1.8765e+00, -2.4453e+00,  1.9808e+00, -5.3129e-01,\n",
       "          -5.6349e-01,  5.8820e-01,  1.2491e+00,  3.3431e-01, -2.7784e-01],\n",
       "         [-1.5092e+00,  2.5521e-01, -3.1735e-01, -1.1411e+00, -1.6520e-01,\n",
       "          -2.3153e-01, -8.0766e-01,  4.4893e-03,  1.3732e+00, -2.8607e-01],\n",
       "         [-8.0253e-01, -7.0302e-01,  2.2962e-01,  9.8649e-01, -1.7119e+00,\n",
       "           1.0719e+00, -8.9096e-01,  8.4928e-01, -4.6716e-01,  6.2982e-01]],\n",
       "\n",
       "        [[ 4.4921e-01,  9.5941e-01, -4.1672e-01,  1.2233e+00,  1.3751e-01,\n",
       "          -1.2113e+00, -6.4372e-01, -2.4151e+00, -9.2423e-01, -8.9682e-01],\n",
       "         [-1.3205e+00, -3.7497e-01,  2.7442e-01, -1.5866e-01,  4.5743e-01,\n",
       "           1.6316e+00, -1.1607e+00, -9.8618e-02, -1.0705e+00, -1.7953e+00],\n",
       "         [ 1.2105e+00, -1.5109e+00,  1.9763e+00, -8.8220e-02,  5.8920e-01,\n",
       "          -2.1110e+00, -6.1063e-01, -4.2220e-01,  5.9942e-01, -1.8422e+00]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输入一个三维向量，序列长度是5，batchsize的大小是3，数据的维度是10\n",
    "input = torch.randn(5, 3, 10)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e4e8180d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 10])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0cc4ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义这个神经网络的输入维度10，输出维度是20，有2层\n",
    "rnn = nn.LSTM(10, 20, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d5c800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里定义隐藏层有2层，batchsize是3，数据输出维度20\n",
    "h_0 = torch.randn(2, 3, 20)\n",
    "#这里定义细胞结构有2层，batchsize是3，数据输出维度20\n",
    "c_0 = torch.randn(2, 3, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc048f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (h_n,c_n)= rnn(input, (h_0, c_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c06c738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3604,  0.5154,  0.0711, -0.2352, -0.3483,  0.3091, -0.1215,\n",
       "          -0.0475, -0.0412, -0.3772,  0.0706,  0.1233, -0.1183,  0.3506,\n",
       "           0.1431,  0.5162, -0.1927, -0.3727, -0.0917,  0.2457],\n",
       "         [ 0.5643,  0.2944, -0.1171, -0.6255,  0.1865, -0.5595, -0.2428,\n",
       "          -0.1065, -0.1247, -0.1740, -0.1951,  0.4056,  0.2493,  0.1001,\n",
       "           0.4570,  0.2602, -0.3528,  0.1118, -0.3984,  0.2136],\n",
       "         [-0.0215,  0.4137,  0.3563,  0.3736, -0.2950, -0.3326,  0.0533,\n",
       "           0.0849, -0.4866,  0.1907, -0.3113, -0.2270, -0.0584, -0.0878,\n",
       "           0.1643, -0.0978, -0.0408,  0.1756, -0.1073,  0.4127]],\n",
       "\n",
       "        [[ 0.2799,  0.2577,  0.0685, -0.2101, -0.1080,  0.2490, -0.1663,\n",
       "          -0.0728,  0.0122, -0.1475,  0.1249,  0.0437, -0.0843,  0.2203,\n",
       "           0.0721,  0.1660, -0.1027, -0.2771, -0.0479,  0.1159],\n",
       "         [ 0.2275,  0.2957, -0.0434, -0.3822,  0.0813, -0.2542, -0.2015,\n",
       "          -0.1910, -0.1532, -0.1752, -0.1095,  0.0989,  0.0791,  0.0142,\n",
       "           0.1530,  0.1403, -0.1555, -0.0349, -0.2191,  0.0813],\n",
       "         [ 0.1264,  0.2312,  0.2049,  0.2316, -0.1027, -0.2025,  0.0332,\n",
       "           0.0643, -0.1783,  0.1606, -0.2009, -0.1799, -0.0527, -0.0319,\n",
       "           0.0201, -0.0161,  0.0327,  0.0038, -0.0698,  0.3590]],\n",
       "\n",
       "        [[ 0.2399,  0.1987,  0.0483, -0.1757,  0.0192,  0.0977, -0.1887,\n",
       "          -0.0630,  0.0411, -0.0647,  0.1171,  0.0225, -0.0590,  0.1433,\n",
       "           0.0361,  0.0507, -0.0963, -0.1855, -0.0121, -0.0082],\n",
       "         [ 0.1750,  0.1964, -0.0047, -0.2722,  0.0971, -0.1464, -0.1571,\n",
       "          -0.1554, -0.1290, -0.0659, -0.0693,  0.0096,  0.0020,  0.0306,\n",
       "           0.0193,  0.0515, -0.1212, -0.0890, -0.1396,  0.0021],\n",
       "         [ 0.1562,  0.1911,  0.1257,  0.1689,  0.0442, -0.1778, -0.0194,\n",
       "           0.0299, -0.0808,  0.1804, -0.1188, -0.0914, -0.0181,  0.0086,\n",
       "          -0.0213, -0.0570,  0.0195, -0.0606, -0.0189,  0.2767]],\n",
       "\n",
       "        [[ 0.2430,  0.1697,  0.0627, -0.1448,  0.0655, -0.0103, -0.1790,\n",
       "          -0.0328,  0.0267,  0.0162,  0.0962, -0.0318, -0.0377,  0.1150,\n",
       "           0.0104,  0.0144, -0.0873, -0.1604, -0.0343, -0.0671],\n",
       "         [ 0.1766,  0.1407,  0.0105, -0.1707,  0.1121, -0.1033, -0.1103,\n",
       "          -0.1069, -0.1272,  0.0082, -0.0503, -0.0294, -0.0159,  0.0436,\n",
       "          -0.0304,  0.0023, -0.0908, -0.1027, -0.1038, -0.0292],\n",
       "         [ 0.1988,  0.1901,  0.0734,  0.0939,  0.0948, -0.1957, -0.0040,\n",
       "           0.0167, -0.0604,  0.1515, -0.0563, -0.0701, -0.0098,  0.0423,\n",
       "          -0.0281, -0.0293,  0.0024, -0.0789,  0.0065,  0.1896]],\n",
       "\n",
       "        [[ 0.2321,  0.1606,  0.0823, -0.0938,  0.1104, -0.0658, -0.1930,\n",
       "          -0.0301, -0.0101,  0.0679,  0.0693, -0.0351, -0.0172,  0.0948,\n",
       "           0.0146, -0.0371, -0.0874, -0.1333, -0.0089, -0.0920],\n",
       "         [ 0.1959,  0.1301,  0.0259, -0.1169,  0.1337, -0.0944, -0.1091,\n",
       "          -0.0968, -0.1086,  0.0367, -0.0304, -0.0313, -0.0202,  0.0352,\n",
       "          -0.0340, -0.0410, -0.0950, -0.1016, -0.0468, -0.0670],\n",
       "         [ 0.1999,  0.1439,  0.0723,  0.0488,  0.1174, -0.1703, -0.0378,\n",
       "           0.0067, -0.0208,  0.1301, -0.0398, -0.0450,  0.0025,  0.0635,\n",
       "          -0.0427, -0.0263, -0.0050, -0.0822,  0.0314,  0.1011]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60efa34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2534,  0.1517, -0.2272, -0.2379,  0.0810, -0.1336,  0.2135,\n",
       "          -0.0892,  0.0149,  0.2816, -0.1149,  0.0479,  0.0180,  0.0805,\n",
       "          -0.2502,  0.1231,  0.0006, -0.0087, -0.0048, -0.0820],\n",
       "         [ 0.0600,  0.1964,  0.0666,  0.0105,  0.2475,  0.1037,  0.2565,\n",
       "          -0.0217, -0.1633,  0.2251, -0.1423, -0.1041,  0.1163, -0.0169,\n",
       "          -0.1894,  0.0076, -0.2073,  0.1783,  0.0453,  0.1975],\n",
       "         [ 0.0736,  0.1269,  0.0633,  0.1144,  0.1661, -0.1076,  0.1930,\n",
       "           0.0030, -0.0846,  0.1921, -0.0753,  0.0608,  0.1503,  0.0682,\n",
       "          -0.0943, -0.0614, -0.1420,  0.1475,  0.2195,  0.0525]],\n",
       "\n",
       "        [[ 0.2321,  0.1606,  0.0823, -0.0938,  0.1104, -0.0658, -0.1930,\n",
       "          -0.0301, -0.0101,  0.0679,  0.0693, -0.0351, -0.0172,  0.0948,\n",
       "           0.0146, -0.0371, -0.0874, -0.1333, -0.0089, -0.0920],\n",
       "         [ 0.1959,  0.1301,  0.0259, -0.1169,  0.1337, -0.0944, -0.1091,\n",
       "          -0.0968, -0.1086,  0.0367, -0.0304, -0.0313, -0.0202,  0.0352,\n",
       "          -0.0340, -0.0410, -0.0950, -0.1016, -0.0468, -0.0670],\n",
       "         [ 0.1999,  0.1439,  0.0723,  0.0488,  0.1174, -0.1703, -0.0378,\n",
       "           0.0067, -0.0208,  0.1301, -0.0398, -0.0450,  0.0025,  0.0635,\n",
       "          -0.0427, -0.0263, -0.0050, -0.0822,  0.0314,  0.1011]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(h_n.shape)\n",
    "h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "530a8bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 20])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9f7bff76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 20])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "526ea296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_n.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9823aa3",
   "metadata": {},
   "source": [
    "## lstm实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "18ce0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1cc8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "96f5e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "80283b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练数据和测试数据\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "70856d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5a681765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9c4638d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义神经网络\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, (h_n,c_n) = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])# 此处的-1说明我们只取RNN最后输出的那个hn\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a5568e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "97655966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数和优化器\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6f480c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.6730\n",
      "Epoch [1/2], Step [200/600], Loss: 0.4397\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2468\n",
      "Epoch [1/2], Step [400/600], Loss: 0.2396\n",
      "Epoch [1/2], Step [500/600], Loss: 0.2224\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1711\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1211\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0603\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0458\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1313\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1638\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0613\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.train()\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "415cca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 97.54 %\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57252e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
